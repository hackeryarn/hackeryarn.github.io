<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ruby on hackeryarn</title>
    <link>https://hackeryarn.com/categories/ruby/</link>
    <description>Recent content in Ruby on hackeryarn</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 11 Jun 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://hackeryarn.com/categories/ruby/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Efficient CSV Imports in Rails</title>
      <link>https://hackeryarn.com/post/rails-csv-imports/</link>
      <pubDate>Sun, 11 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://hackeryarn.com/post/rails-csv-imports/</guid>
      <description>Rails has great capabilities for working CSV files. However, like with many things, the most obvious way is not the most efficient.
We noticed this when our server had major fluctuations in memory consumption. After digging through metrics, made easy thanks to Prometheus and Grafana. We noticed that the spikes were due to our CSV uploads.
Examining CSV Import Our processor is responsible for bringing in coordinates from legacy systems and ones that cannot support our API.</description>
    </item>
    
  </channel>
</rss>